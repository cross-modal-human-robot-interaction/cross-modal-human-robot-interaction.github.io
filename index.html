<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Human Interaction for Robot Navigation - Index</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/line-awesome/css/line-awesome.min.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Serenity - v2.2.1
  * Template URL: https://bootstrapmade.com/serenity-bootstrap-corporate-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex">

      <div class="logo mr-auto">
        <h1 class="text-light"><a href="index.html">Cross-modal Human-robot Interaction (2nd)</a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav class="nav-menu d-none d-lg-block">
        <ul>
          <li><a href="call.html">Call for submissions</a></li>
          <li><a href="speakers.html">Speakers</a></li>
          <li><a href="organizers.html">Organizers</a></li>
          <li><a href="schedule.html">Schedule</a></li>
          <li><a href="challenge.html">Challenge</a></li>
        </ul>
      </nav><!-- .nav-menu -->

    </div>
  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container" data-aos="fade-up">
      <h1>ECCV 2022 Workshop: Cross-modal Human-robot Interaction (2nd)</h1>
      <br> 
      <br> 
      <h2><b>When:</b> Oct, 24, 2022
        <b>Where:</b> Virtual (ECCV 2022)</h2>
      <!-- <a href="#about" class="btn-get-started scrollto">Get Started</a> -->
    </div>
  </section><!-- End Hero -->

  <main id="main">

    <section id="about" class="about">

    <div class="container" data-aos="fade-up">

      <div class="row">

        <div class="col-lg-12" style="height: 30px"></div>

        <div class="col-lg-2"></div>

        <div class="col-lg-8">
          <h2> Workshop Information </h2>
          <!-- <strong>The video of our workshop has been avaliable <a href="https://www.youtube.com/watch?v=a-PgM2P5GSQ">Here</a>. </strong>  -->
          <strong>The 1st workshop Human Interaction for Robotic Navigation is avaliable <a href="https://human-interaction4robotic-navigation.github.io/index.html">Here</a>. </strong> 
        </div>

        <div class="col-lg-2"></div>

        <div class="col-lg-12" style="height: 30px"></div>

        <div class="col-lg-2"></div>

        <div class="col-lg-8">
           Building a robot to navigate with human interaction is a topic that has been researched for a long time. 
          Many methods are able to solve human interaction for robot navigation from diverse aspects. 
          Computer vision methods like detection, segmentation and visual grounding enable the robot to understand the semantics in an environment. 
          Imitation learning and reinforcement learning with a deep neural network contribute a lot for learning a robust navigation policy. 
          Simultaneous localization and mapping (SLAM) and planning methods enable a robot for long-term navigation. 
          On the other hand, embodied navigation following a natural language instruction attracts rising attention due to its wide application. 
          Diverse tasks such as vision-language navigation (VLN), embodied question answering (EQA), visual-dialog navigation (VDN) are proposed. 
        </div>
        
        <div class="col-lg-2"></div>

        <div class="col-lg-12" style="height: 30px"></div>

        <div class="col-lg-2"></div>
        
        <div class="col-lg-8">
          There are many efforts to incorporate natural language processing and vision-language alignment into a navigation model to enable its language comprehension ability. 
          Moreover, since there exists a large domain gap between a simulated environment and the real physical environment, some researchers adopt transfer learning methods to reduce the domain gap. 
          Many research works have been devoted to related topics, leading to rapid growth of related publications in the top-tier conferences and journals.
        </div>

        <div class="col-lg-2"></div>

        <div class="col-lg-12" style="height: 30px"></div>

        <div class="col-lg-2"></div>

        <div class="col-lg-8">
          This workshop will investigate current ways of human-robot interaction in the senario of robot navigation to give a promising direction of robot-human interaction. The topics of the workshop include (but not limited to):
          <ul>
            <li>visual-based navigation</li>
            <li>Reinforcement learning, policy exploration ​for navigation</li>
            <li>Vision-based ​ simultaneous localization and mapping (SLAM), planning</li>
            <li>Vision-language navigation, visual-dialog navigation and other cross-modal visual navigation</li>
            <li>Vision-language grounding, visual commonsense reasoning</li>
            <li>Navigation applications involving humans, e.g. indoor robots, UAV, auto-driving, gaming AI, etc.</li>
            <li>New datasets and metrics to evaluate the benefit of the robot navigation approaches for the specific embodied navigation problems</li>
          </ul>
        </div>
      </div>
    </div>
  </section>
  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="credits">
        Contact Us: <a href="mailto: hi4rn@googlegroups.com">hi4rn@googlegroups.com</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
